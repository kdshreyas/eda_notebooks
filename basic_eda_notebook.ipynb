{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd653b82-3111-49c1-a0c3-f57b3e4f540c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with missing values:\n",
      "Index(['director', 'cast', 'country', 'date_added', 'rating', 'duration'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('netflix_titles.csv')\n",
    "\n",
    "# Handle Missing Values\n",
    "missing_columns = df.columns[df.isnull().any()]  # Identify columns with missing values\n",
    "print(\"Columns with missing values:\")\n",
    "print(missing_columns)\n",
    "\n",
    "# Option 1: Drop rows or columns with missing values\n",
    "# df.dropna(inplace=True)  # Uncomment this line to drop rows with missing values\n",
    "# df.dropna(axis=1, inplace=True)  # Uncomment this line to drop columns with missing values\n",
    "\n",
    "# Option 2: Fill missing values with appropriate values\n",
    "# Example: Fill missing values in numeric columns with the mean\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "df[numeric_columns] = df[numeric_columns].fillna(df[numeric_columns].mean())\n",
    "\n",
    "# Example: Fill missing values in categorical columns with the mode\n",
    "categorical_columns = df.select_dtypes(include=[np.object_]).columns\n",
    "df[categorical_columns] = df[categorical_columns].fillna(df[categorical_columns].mode().iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bc9432-7740-4faf-b0b8-5c010a441127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Duplicate Records\n",
    "# Example: Identify and remove duplicate records based on all columns\n",
    "duplicate_records = df.duplicated()\n",
    "df_no_duplicates = df[~duplicate_records]\n",
    "\n",
    "# Display cleaned data\n",
    "print(\"Cleaned DataFrame:\")\n",
    "print(df_no_duplicates.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76199425-21ab-423e-97ae-a97569e9fae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with Outliers\n",
    "# Example: Identify and remove outliers using z-scores\n",
    "z_scores = np.abs((df[numeric_columns] - df[numeric_columns].mean()) / df[numeric_columns].std())\n",
    "outlier_threshold = 3  # Adjust the threshold as needed\n",
    "df_no_outliers = df[(z_scores < outlier_threshold).all(axis=1)]\n",
    "\n",
    "# Example: Transform outliers using winsorization\n",
    "from scipy.stats import mstats\n",
    "df_winsorized = pd.DataFrame(\n",
    "    mstats.winsorize(df[numeric_columns].values, limits=[0.05, 0.05]),\n",
    "    columns=numeric_columns\n",
    ")\n",
    "\n",
    "\n",
    "# Resolve Inconsistencies\n",
    "# Example: Check and correct inconsistent formats\n",
    "# df['date_column'] = pd.to_datetime(df['date_column'], format='%Y-%m-%d')\n",
    "\n",
    "# Example: Standardize units\n",
    "# df['weight_column'] = df['weight_column'] * 0.453592  # Convert pounds to kilograms\n",
    "\n",
    "# Example: Correct inconsistent categorical values\n",
    "# df['category_column'].replace({'A1': 'A', 'A2': 'A'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b2a84f-0f77-474f-9400-c3c8ec4ac768",
   "metadata": {},
   "source": [
    "In this part, missing values in numeric columns are interpolated. Interpolation is a technique to estimate missing values based on the surrounding data points. It fills in the missing values with values that are calculated based on the neighboring values. The interpolate() function in pandas performs this interpolation for numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85ec70ca-b5e9-4d1c-9657-0bb2274ef680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 3: Use advanced techniques like interpolation or imputation\n",
    "# Example: Interpolate missing values in numeric columns\n",
    "df[numeric_columns] = df[numeric_columns].interpolate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f63cd9-8fe5-4b12-87db-70591925fa97",
   "metadata": {},
   "source": [
    "Here, outliers in the numeric columns are identified and removed. Z-scores are calculated by subtracting the column mean from each data point and then dividing it by the column standard deviation. The z-scores indicate how many standard deviations away a data point is from the mean. By setting a threshold (e.g., 3), we consider values beyond that threshold as outliers. The DataFrame df_no_outliers contains the data without the identified outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dedb15c5-d014-406c-b81e-8810e67f9574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with Outliers\n",
    "# Example: Identify and remove outliers using z-scores\n",
    "z_scores = np.abs((df[numeric_columns] - df[numeric_columns].mean()) / df[numeric_columns].std())\n",
    "outlier_threshold = 3  # Adjust the threshold as needed\n",
    "df_no_outliers = df[(z_scores < outlier_threshold).all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc875f69-ae62-4b9a-94bb-bdcdc8bb220d",
   "metadata": {},
   "source": [
    "This example shows an alternative approach to dealing with outliers using winsorization. Winsorization transforms extreme values to a specified percentile of the data. The winsorize() function from the scipy.stats module is used to perform winsorization. The DataFrame df_winsorized contains the winsorized values for the numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1354fbd-2743-4f72-94ce-ea9274133c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>release_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8802</th>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8803</th>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8804</th>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8805</th>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8806</th>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8807 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      release_year\n",
       "0             2020\n",
       "1             2021\n",
       "2             2021\n",
       "3             2021\n",
       "4             2021\n",
       "...            ...\n",
       "8802          2007\n",
       "8803          2018\n",
       "8804          2009\n",
       "8805          2006\n",
       "8806          2015\n",
       "\n",
       "[8807 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Transform outliers using winsorization\n",
    "from scipy.stats import mstats\n",
    "df_winsorized = pd.DataFrame(\n",
    "    mstats.winsorize(df[numeric_columns].values, limits=[0.05, 0.05]),\n",
    "    columns=numeric_columns\n",
    ")\n",
    "df_winsorized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e3b058-2f93-401a-bc62-fc1ebff34408",
   "metadata": {},
   "source": [
    "These examples demonstrate how to handle inconsistencies in the data. The first example converts a column named 'date_column' to a consistent date format using the pd.to_datetime() function. The second example demonstrates standardizing units by multiplying a column named 'weight_column' by a conversion factor (e.g., from pounds to kilograms). The third example corrects inconsistent categorical values by using the replace() function to map specific values to desired values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b91782c8-11b2-4748-8eb7-a115bf5a320d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolve Inconsistencies\n",
    "# Example: Check and correct inconsistent formats\n",
    "# df['date_column'] = pd.to_datetime(df['date_column'], format='%Y-%m-%d')\n",
    "\n",
    "# Example: Standardize units\n",
    "# df['weight_column'] = df['weight_column'] * 0.453592  # Convert pounds to kilograms\n",
    "\n",
    "# Example: Correct inconsistent categorical values\n",
    "# df['category_column'].replace({'A1': 'A', 'A2': 'A'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85662806-be57-4bcf-af6c-943b69bc1035",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d3b6a6a-d714-49ef-86de-bcc65ac8519f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 8807\n",
      "Number of columns: 12\n",
      "Data Types:\n",
      "show_id         object\n",
      "type            object\n",
      "title           object\n",
      "director        object\n",
      "cast            object\n",
      "country         object\n",
      "date_added      object\n",
      "release_year     int64\n",
      "rating          object\n",
      "duration        object\n",
      "listed_in       object\n",
      "description     object\n",
      "dtype: object\n",
      "Data Structure:\n",
      "  show_id     type                  title         director  \\\n",
      "0      s1    Movie   Dick Johnson Is Dead  Kirsten Johnson   \n",
      "1      s2  TV Show          Blood & Water    Rajiv Chilaka   \n",
      "2      s3  TV Show              Ganglands  Julien Leclercq   \n",
      "3      s4  TV Show  Jailbirds New Orleans    Rajiv Chilaka   \n",
      "4      s5  TV Show           Kota Factory    Rajiv Chilaka   \n",
      "\n",
      "                                                cast        country  \\\n",
      "0                                 David Attenborough  United States   \n",
      "1  Ama Qamata, Khosi Ngema, Gail Mabalane, Thaban...   South Africa   \n",
      "2  Sami Bouajila, Tracy Gotoas, Samuel Jouy, Nabi...  United States   \n",
      "3                                 David Attenborough  United States   \n",
      "4  Mayur More, Jitendra Kumar, Ranjan Raj, Alam K...          India   \n",
      "\n",
      "           date_added  release_year rating   duration  \\\n",
      "0  September 25, 2021          2020  PG-13     90 min   \n",
      "1  September 24, 2021          2021  TV-MA  2 Seasons   \n",
      "2  September 24, 2021          2021  TV-MA   1 Season   \n",
      "3  September 24, 2021          2021  TV-MA   1 Season   \n",
      "4  September 24, 2021          2021  TV-MA  2 Seasons   \n",
      "\n",
      "                                           listed_in  \\\n",
      "0                                      Documentaries   \n",
      "1    International TV Shows, TV Dramas, TV Mysteries   \n",
      "2  Crime TV Shows, International TV Shows, TV Act...   \n",
      "3                             Docuseries, Reality TV   \n",
      "4  International TV Shows, Romantic TV Shows, TV ...   \n",
      "\n",
      "                                         description  \n",
      "0  As her father nears the end of his life, filmm...  \n",
      "1  After crossing paths at a party, a Cape Town t...  \n",
      "2  To protect his family from a powerful drug lor...  \n",
      "3  Feuds, flirtations and toilet talk go down amo...  \n",
      "4  In a city of coaching centers known to train I...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Examine Data Structure\n",
    "num_rows = df.shape[0]\n",
    "num_cols = df.shape[1]\n",
    "print(\"Number of rows:\", num_rows)\n",
    "print(\"Number of columns:\", num_cols)\n",
    "print(\"Data Types:\")\n",
    "print(df.dtypes)\n",
    "print(\"Data Structure:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fdf78e-27d2-4e0e-bbee-6de03d177b66",
   "metadata": {},
   "source": [
    "Count: It tells you how many values are available for each numerical column. If some columns have fewer values compared to others, it means there may be missing data in those columns.\n",
    "\n",
    "Mean: It gives you an idea of the typical value for each numerical column. It's like finding the average of all the values in that column.\n",
    "\n",
    "Standard Deviation: It shows you how spread out the values are in each numerical column. A higher standard deviation means the values are more spread out, while a lower standard deviation means the values are closer together.\n",
    "\n",
    "Minimum and Maximum: They tell you the smallest and largest values in each numerical column, respectively. They give you an idea of the range of values covered by each variable.\n",
    "\n",
    "Quartiles: They help you understand the distribution of the data. The first quartile represents the value below which 25% of the data falls, the median represents the middle value, and the third quartile represents the value below which 75% of the data falls.\n",
    "\n",
    "By looking at these summary statistics, you can get an overall understanding of your numerical data. You can see how many values are available, the typical value, how spread out the values are, the range of values, and the distribution of the data. This information can help you identify any missing data, outliers, or unusual patterns in your dataset.\n",
    "\n",
    "\n",
    "Missing Data: The count in the summary statistics provides the number of non-missing values for each numerical column. If a column has significantly fewer values compared to others, it indicates the presence of missing data. By observing the count values, you can identify which columns may have missing values and may require further investigation or handling.\n",
    "\n",
    "Outliers: Outliers are extreme values that are significantly different from the majority of the data points. The minimum, maximum, and quartile values in the summary statistics give you an understanding of the range of values covered by each variable. By comparing these values, you can identify potential outliers. For example, if the maximum value is much larger or smaller than the majority of values, it suggests the presence of outliers. Outliers can be important to investigate further, as they may impact your analysis or indicate data issues.\n",
    "\n",
    "Unusual Patterns: Summary statistics provide insights into the distribution of the data. By examining the mean, standard deviation, and quartile values, you can get a sense of the overall pattern and variability in the data. If you observe unusual patterns, such as a large standard deviation or significant differences between quartile values, it may indicate the presence of unusual data patterns or data quality issues. This can prompt you to investigate further and explore the underlying reasons behind these patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19e15d5e-360c-4a43-bd55-a8bc9ef57d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics:\n",
      "       release_year\n",
      "count   8807.000000\n",
      "mean    2014.180198\n",
      "std        8.819312\n",
      "min     1925.000000\n",
      "25%     2013.000000\n",
      "50%     2017.000000\n",
      "75%     2019.000000\n",
      "max     2021.000000\n"
     ]
    }
   ],
   "source": [
    "# Summarize Data\n",
    "summary_stats = df.describe()\n",
    "print(\"Summary Statistics:\")\n",
    "print(summary_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72226022-8bd5-47d4-8ca4-0d7b8b614d54",
   "metadata": {},
   "source": [
    "The histogram helps you visualize the distribution of the numerical variable, showing the frequency or count of values within each bin. It allows you to observe the shape of the distribution, identify peaks or clusters, and get a sense of the spread or concentration of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4432d3c-81e5-44a1-b710-055dfcee997a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Data\n",
    "# Example: Histogram for a numerical variable\n",
    "plt.hist(df['numeric_variable'], bins=10)\n",
    "plt.xlabel('Numeric Variable')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Numeric Variable')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8febf4-a3b7-450c-a073-382144025000",
   "metadata": {},
   "source": [
    "The bar plot helps you visualize the distribution of the categorical variable by showing the count or frequency of each category as individual bars. It allows you to compare the relative sizes of different categories and identify the dominant or minority categories. The rotation of the x-axis tick labels is often used to improve readability when there are many categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d6ce7a-1163-4adf-87eb-5b774841fef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Bar plot for a categorical variable\n",
    "plt.bar(df['categorical_variable'].value_counts().index, df['categorical_variable'].value_counts().values)\n",
    "plt.xlabel('Categories')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Bar Plot of Categorical Variable')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955c91c7-7764-454e-85d6-0aa1c99ff05c",
   "metadata": {},
   "source": [
    "The correlation matrix and heatmap help you identify relationships between numerical variables in your dataset. By examining the color patterns in the heatmap, you can quickly spot variables that are strongly positively or negatively correlated. This information is valuable for understanding dependencies between variables and identifying potential predictors or factors that influence each other.\n",
    "\n",
    "The heatmap visualization allows you to identify clusters or groups of variables with similar correlations, helping you uncover underlying patterns and relationships in your data. The annotation of correlation values on the heatmap provides a numerical representation of the strength of the relationships between variables.\n",
    "\n",
    "Remember that correlation does not imply causation, and it's important to interpret the results in the context of your specific data and domain knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1f837b-0d6c-4adc-8d88-ebcea26982ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify Relationships\n",
    "# Example: Correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e48aee-a3bc-4d92-9cb1-12bc06b3ea75",
   "metadata": {},
   "source": [
    "The box plot provides several key insights into the distribution of the numerical variable:\n",
    "\n",
    "It shows the median, which represents the central tendency or the middle value of the data.\n",
    "The box represents the interquartile range (IQR), which spans the middle 50% of the data. The lower boundary of the box is the 25th percentile, and the upper boundary is the 75th percentile.\n",
    "The whiskers extend to the minimum and maximum non-outlier values within 1.5 times the IQR. Any data points beyond the whiskers are considered outliers and are plotted individually.\n",
    "The individual points outside the whiskers represent potential outliers in the data.\n",
    "By examining the box plot, you can quickly identify the median, the spread of the data (IQR), and any outliers or extreme values. This helps you understand the shape of the distribution, the presence of skewness or asymmetry, and the potential need for data transformations or outlier handling.\n",
    "\n",
    "Remember to interpret the box plot in the context of your specific data and domain knowledge to gain meaningful insights about the distribution of the numerical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b0f726-6a09-4cce-82b1-518d443cbf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze Distributions\n",
    "# Example: Box plot for a numerical variable\n",
    "sns.boxplot(x=df['numeric_variable'])\n",
    "plt.xlabel('Numeric Variable')\n",
    "plt.title('Box Plot of Numeric Variable')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687d9823-1160-4512-923c-53db34d9aa1f",
   "metadata": {},
   "source": [
    "The grouping and aggregation process allows you to analyze your data at a more granular level by creating subsets based on a categorical variable and calculating summary statistics or aggregating values within each group. In this example, you calculate the mean of the numerical variable for each unique value of the categorical variable.\n",
    "\n",
    "By examining the grouped data, you can gain insights into how the numerical variable varies across different categories. It helps you understand the average or typical values of the numerical variable within each category and identify any patterns, trends, or differences between the groups.\n",
    "\n",
    "You can apply various aggregation functions (e.g., mean, sum, count, min, max, etc.) to obtain different summary statistics based on your analysis goals. Grouping and aggregating data is particularly useful for conducting exploratory data analysis and understanding the relationships between categorical and numerical variables in your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506c9304-66fe-4681-9452-d2656f193049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping and Aggregation\n",
    "# Example: Group by a categorical variable and calculate mean of a numerical variable\n",
    "grouped_data = df.groupby('categorical_variable')['numeric_variable'].mean()\n",
    "print(\"Grouped Data:\")\n",
    "print(grouped_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b38a049-9111-4d7c-98d3-265b751c573d",
   "metadata": {},
   "source": [
    "For Numerical Columns:\n",
    "\n",
    "Line Plot: Suitable for visualizing the relationship between two numerical variables over a continuous interval.\n",
    "\n",
    "Scatter Plot: Useful for exploring the relationship between two numerical variables as individual data points.\n",
    "\n",
    "Histogram: Ideal for examining the distribution of a numerical variable.\n",
    "\n",
    "Box Plot: Helpful for visualizing the summary statistics (median, quartiles, outliers) of a numerical variable.\n",
    "\n",
    "Violin Plot: Similar to a box plot, but also shows the distribution of the numerical variable across different categories.\n",
    "\n",
    "Area Plot: Useful for illustrating the cumulative contribution or stacked proportions of numerical variables over time or a continuous axis.\n",
    "\n",
    "For Categorical Columns:\n",
    "\n",
    "Bar Plot: Suitable for comparing and displaying the distribution of categorical variables.\n",
    "\n",
    "Pie Chart: Helpful for representing the composition or proportion of different categories in a dataset.\n",
    "\n",
    "Heatmap: Suitable for visualizing the relationship and patterns between two categorical variables.\n",
    "\n",
    "Violin Plot: Can also be used to show the distribution of a numerical variable across different categories.\n",
    "\n",
    "For both Numerical and Categorical Columns:\n",
    "\n",
    "Pair Plot: Suitable for generating pairwise scatter plots for multiple numerical variables, but can also display the relationship between a numerical and a categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9f2066-726f-48f2-a52b-39c54418476d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Line Plot\n",
    "plt.plot(df['x'], df['y'])\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Line Plot')\n",
    "plt.show()\n",
    "\n",
    "# Scatter Plot\n",
    "plt.scatter(df['x'], df['y'])\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Scatter Plot')\n",
    "plt.show()\n",
    "\n",
    "# Histogram\n",
    "plt.hist(df['numeric_variable'], bins=10)\n",
    "plt.xlabel('Numeric Variable')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram')\n",
    "plt.show()\n",
    "\n",
    "# Box Plot\n",
    "plt.boxplot(df['numeric_variable'])\n",
    "plt.xlabel('Numeric Variable')\n",
    "plt.title('Box Plot')\n",
    "plt.show()\n",
    "\n",
    "# Violin Plot\n",
    "sns.violinplot(x=df['category_variable'], y=df['numeric_variable'])\n",
    "plt.xlabel('Category Variable')\n",
    "plt.ylabel('Numeric Variable')\n",
    "plt.title('Violin Plot')\n",
    "plt.show()\n",
    "\n",
    "# Area Plot\n",
    "plt.stackplot(df['x'], df['y1'], df['y2'], labels=['Y1', 'Y2'])\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Area Plot')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Bar Plot\n",
    "plt.bar(df['category_variable'], df['count_variable'])\n",
    "plt.xlabel('Category Variable')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Bar Plot')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "# Pie Chart\n",
    "plt.pie(df['count_variable'], labels=df['category_variable'], autopct='%1.1f%%')\n",
    "plt.title('Pie Chart')\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "# Heatmap\n",
    "heatmap_data = df.pivot(index='category_variable1', columns='category_variable2', values='count_variable')\n",
    "sns.heatmap(heatmap_data, cmap='coolwarm')\n",
    "plt.title('Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# Violin Plot (for categorical variable)\n",
    "sns.violinplot(x=df['category_variable'], y=df['numeric_variable'])\n",
    "plt.xlabel('Category Variable')\n",
    "plt.ylabel('Numeric Variable')\n",
    "plt.title('Violin Plot')\n",
    "plt.show()\n",
    "\n",
    "# Pair Plot\n",
    "sns.pairplot(df[['numeric_variable1', 'numeric_variable2', 'category_variable']])\n",
    "plt.title('Pair Plot')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7419b00d-9067-49e1-95b9-9da84e56b2e4",
   "metadata": {},
   "source": [
    "For Numerical Columns:\n",
    "\n",
    "Kernel Density Plot: Estimates the probability density function of a continuous variable.\n",
    "\n",
    "Scatter Matrix Plot: Displays pairwise scatter plots for multiple numerical variables.\n",
    "\n",
    "Line Plot with Error Bars: Represents the trend of a numerical variable over time or other continuous interval, along with the uncertainty or variability using error bars.\n",
    "\n",
    "Contour Plot: Visualizes three-dimensional data by displaying contours of equal values on a two-dimensional plane.\n",
    "\n",
    "QQ Plot: Compares the quantiles of a dataset to the quantiles of a theoretical distribution, aiding in assessing the distributional fit.\n",
    "\n",
    "Andrews Curves: Converts each data point into a curve based on the feature values and plots them, allowing for visual analysis of clusters or patterns.\n",
    "\n",
    "For Categorical Columns:\n",
    "\n",
    "Stacked Bar Plot: Shows the composition of categories within a variable and how it changes across groups.\n",
    "\n",
    "Grouped Bar Plot: Compares the distribution of a categorical variable across different groups.\n",
    "\n",
    "Word Cloud: Displays the frequency or importance of words in a text-based dataset using varying font sizes.\n",
    "\n",
    "Sankey Diagram: Visualizes the flow or distribution of categorical data between different categories or stages.\n",
    "\n",
    "Chord Diagram: Illustrates the relationships and flows between different categorical variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec78f8ca-779e-4066-870a-4279178c9fe0",
   "metadata": {},
   "source": [
    "Determine the key questions:\n",
    "\n",
    "Start by understanding the purpose of your data analysis and what insights you want to gain from it.\n",
    "\n",
    "Identify the key questions or objectives you want to address with data visualization.\n",
    "\n",
    "These questions should guide your analysis and visualization choices.\n",
    "Select appropriate visualizations:\n",
    "\n",
    "Based on the key questions and the nature of your data (numerical or categorical), choose the most suitable visualization techniques to explore and communicate the insights effectively.\n",
    "\n",
    "Refer to the list of visualization techniques we discussed earlier and select the ones that best represent your data and answer your key questions.\n",
    "\n",
    "Consider the type of data (numerical or categorical), the relationships between variables, the distribution characteristics, and any patterns or trends you want to highlight.\n",
    "\n",
    "Create visualizations:\n",
    "\n",
    "Use the chosen visualization techniques from step 2 to create the visualizations.\n",
    "\n",
    "Use the code snippets provided earlier as a reference and customize them based on your dataset and visualization preferences.\n",
    "\n",
    "Ensure that the visualizations are clear, well-labeled, and visually appealing.\n",
    "\n",
    "Consider adding titles, axis labels, legends, and annotations to provide context and interpretation.\n",
    "\n",
    "Summarize key findings:\n",
    "\n",
    "Analyze the visualizations and extract insights relevant to your key questions.\n",
    "\n",
    "Identify any patterns, trends, or relationships that emerge from the visualizations.\n",
    "\n",
    "Highlight significant observations or noteworthy findings.\n",
    "\n",
    "Use descriptive language to summarize the key findings concisely.\n",
    "\n",
    "Support your findings with evidence from the visualizations, referring to specific charts or plots.\n",
    "\n",
    "Consider providing recommendations or further actions based on the insights gained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e18e65e-56c2-4a85-8d7f-07a25493f375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Data Visualization\n",
    "\n",
    "## Determine the key questions\n",
    "# Define the questions or objectives you want to address with data visualization.\n",
    "\n",
    "## Select appropriate visualizations\n",
    "\n",
    "# Example: Line Plot\n",
    "plt.plot(df['x'], df['y'])\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Line Plot')\n",
    "plt.show()\n",
    "\n",
    "# Example: Scatter Plot\n",
    "plt.scatter(df['x'], df['y'])\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Scatter Plot')\n",
    "plt.show()\n",
    "\n",
    "# Example: Histogram\n",
    "plt.hist(df['numeric_variable'], bins=10)\n",
    "plt.xlabel('Numeric Variable')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram')\n",
    "plt.show()\n",
    "\n",
    "# Example: Box Plot\n",
    "plt.boxplot(df['numeric_variable'])\n",
    "plt.xlabel('Numeric Variable')\n",
    "plt.title('Box Plot')\n",
    "plt.show()\n",
    "\n",
    "# Example: Violin Plot\n",
    "sns.violinplot(x=df['categorical_variable'], y=df['numeric_variable'])\n",
    "plt.xlabel('Categorical Variable')\n",
    "plt.ylabel('Numeric Variable')\n",
    "plt.title('Violin Plot')\n",
    "plt.show()\n",
    "\n",
    "# Example: Area Plot\n",
    "plt.fill_between(df['x'], df['y'], alpha=0.5)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.title('Area Plot')\n",
    "plt.show()\n",
    "\n",
    "## Prepare data for visualization\n",
    "# Perform any necessary data transformations, aggregations, or filtering specific to each visualization.\n",
    "\n",
    "## Create visualizations\n",
    "\n",
    "# Example: Bar Plot\n",
    "plt.bar(df['categorical_variable'].value_counts().index, df['categorical_variable'].value_counts().values)\n",
    "plt.xlabel('Categories')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Bar Plot')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "\n",
    "# Example: Pie Chart\n",
    "plt.pie(df['categorical_variable'].value_counts(), labels=df['categorical_variable'].value_counts().index, autopct='%1.1f%%')\n",
    "plt.title('Pie Chart')\n",
    "plt.show()\n",
    "\n",
    "# Example: Heatmap\n",
    "cross_tab = pd.crosstab(df['categorical_variable1'], df['categorical_variable2'])\n",
    "sns.heatmap(cross_tab, cmap='coolwarm', annot=True)\n",
    "plt.xlabel('Categorical Variable 2')\n",
    "plt.ylabel('Categorical Variable 1')\n",
    "plt.title('Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# Example: Pair Plot\n",
    "sns.pairplot(df, hue='categorical_variable')\n",
    "plt.title('Pair Plot')\n",
    "plt.show()\n",
    "\n",
    "## Customize and enhance visuals\n",
    "# Adjust colors, labels, titles, axes, legends, annotations, etc., to improve clarity and interpretability.\n",
    "\n",
    "## Arrange and organize visuals\n",
    "# Arrange the visualizations in a logical order, considering subplots, grids, or sections for better organization.\n",
    "\n",
    "## Provide clear explanations\n",
    "# Accompany each visualization with clear explanations, highlighting key findings, observations, or trends.\n",
    "\n",
    "## Iterate and refine\n",
    "# Review and revise the visualizations and explanations to improve clarity, impact, and insights.\n",
    "\n",
    "## Summarize key findings\n",
    "# Conclude the data visualization section by summarizing the key findings or patterns observed.\n",
    "\n",
    "# Save or export the final notebook as desired.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a243f701-626a-4adc-a216-bcd0233f2112",
   "metadata": {},
   "source": [
    "Categorical variables can be divided into several types:\n",
    "\n",
    "Nominal: Nominal variables are categorical variables that have no inherent order or hierarchy. The categories are distinct and can't be ranked. Examples include colors (e.g., red, blue, green) or categories like \"dog,\" \"cat,\" and \"bird.\"\n",
    "\n",
    "Ordinal: Ordinal variables have categories that can be ranked or ordered in a meaningful way. The categories have a relative order but not necessarily a specific numerical difference between them. Examples include ratings (e.g., low, medium, high) or educational levels (e.g., elementary, middle, high school).\n",
    "\n",
    "Binary: Binary variables have only two categories or levels. They can represent yes/no, true/false, or presence/absence situations. Examples include gender (male/female), whether a customer made a purchase (yes/no), or a binary outcome in a classification problem.\n",
    "\n",
    "Interval: Interval variables represent categories that have a fixed and equal interval between them. However, they lack a meaningful zero point. Examples include temperature measured in Celsius or Fahrenheit.\n",
    "\n",
    "Ratio: Ratio variables are similar to interval variables but have a meaningful zero point. They have a fixed and equal interval between categories, and the zero point indicates the absence of the variable. Examples include age, weight, height, or income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26a0467-143f-4785-b453-b7d242cd0978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Handling Missing Values\n",
    "# Identify columns or features with missing values\n",
    "missing_columns = df.columns[df.isnull().any()]\n",
    "\n",
    "# Impute missing values with mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df[missing_columns] = imputer.fit_transform(df[missing_columns])\n",
    "\n",
    "# Create new features to indicate missing values\n",
    "df['feature_missing'] = df[missing_columns].isnull().sum(axis=1)\n",
    "\n",
    "# Encoding Categorical Variables\n",
    "# Perform one-hot encoding for categorical variables\n",
    "categorical_columns = df.select_dtypes(include='object').columns\n",
    "df_encoded = pd.get_dummies(df, columns=categorical_columns)\n",
    "\n",
    "# Label encoding for ordinal categorical variables\n",
    "ordinal_columns = ['ordinal_variable']\n",
    "label_encoder = LabelEncoder()\n",
    "df_encoded['ordinal_variable_encoded'] = label_encoder.fit_transform(df['ordinal_variable'])\n",
    "\n",
    "# Feature Scaling and Normalization\n",
    "# Standardize numerical features\n",
    "numerical_columns = df.select_dtypes(include=['int', 'float']).columns\n",
    "scaler = StandardScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df[numerical_columns]), columns=numerical_columns)\n",
    "\n",
    "# Min-max scaling for numerical features\n",
    "minmax_scaler = MinMaxScaler()\n",
    "df_minmax_scaled = pd.DataFrame(minmax_scaler.fit_transform(df[numerical_columns]), columns=numerical_columns)\n",
    "\n",
    "# Creating Interaction or Derived Features\n",
    "# Example: Create interaction feature between two numerical variables\n",
    "df['interaction_feature'] = df['numeric_variable1'] * df['numeric_variable2']\n",
    "\n",
    "# Handling Outliers\n",
    "# Example: Remove outliers using z-scores\n",
    "z_scores = np.abs((df['numeric_variable'] - df['numeric_variable'].mean()) / df['numeric_variable'].std())\n",
    "df_no_outliers = df[z_scores < 3]\n",
    "\n",
    "# Time-based Features\n",
    "# Example: Extract year and month from a date variable\n",
    "df['year'] = pd.to_datetime(df['date_column']).dt.year\n",
    "df['month'] = pd.to_datetime(df['date_column']).dt.month\n",
    "\n",
    "# Dimensionality Reduction\n",
    "# Example: Perform PCA for dimensionality reduction\n",
    "pca = PCA(n_components=2)\n",
    "df_pca = pd.DataFrame(pca.fit_transform(df_scaled), columns=['PC1', 'PC2'])\n",
    "\n",
    "# Summarize the transformed dataset\n",
    "print(\"Transformed Dataset:\")\n",
    "print(df_pca.head())\n",
    "\n",
    "# Save the transformed dataset\n",
    "df_pca.to_csv('transformed_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac83c0c7-9d22-40dd-b6bb-022938949694",
   "metadata": {},
   "source": [
    "To analyze categorical variables based on their type, you can use the following approaches:\n",
    "\n",
    "Nominal Variables:\n",
    "\n",
    "Frequency Counts: Calculate the frequency or count of each category to understand the distribution of nominal variables.\n",
    "Bar Plot: Create a bar plot to visualize the frequency counts of different categories.\n",
    "Cross-Tabulation: Use cross-tabulation or contingency tables to explore the relationship between two or more nominal variables.\n",
    "Ordinal Variables:\n",
    "\n",
    "Frequency Counts: Calculate the frequency or count of each category to understand the distribution of ordinal variables.\n",
    "Bar Plot: Create a bar plot to visualize the frequency counts of different categories, while respecting the ordinal order.\n",
    "Cross-Tabulation: Use cross-tabulation or contingency tables to explore the relationship between an ordinal variable and other categorical or numerical variables.\n",
    "Binary Variables:\n",
    "\n",
    "Frequency Counts: Calculate the frequency or count of each category to understand the distribution of binary variables.\n",
    "Bar Plot: Create a bar plot to visualize the frequency counts of different categories.\n",
    "Cross-Tabulation: Use cross-tabulation or contingency tables to explore the relationship between a binary variable and other categorical or numerical variables.\n",
    "Proportion Analysis: Calculate the proportion or percentage of each category to understand the relative distribution.\n",
    "Interval and Ratio Variables:\n",
    "\n",
    "Summary Statistics: Calculate summary statistics such as mean, median, standard deviation, and quartiles to understand the central tendency and spread of interval and ratio variables.\n",
    "Histogram: Create a histogram to visualize the distribution of interval and ratio variables.\n",
    "Box Plot: Generate a box plot to identify outliers, quartiles, and the overall distribution of interval and ratio variables.\n",
    "Grouping and Aggregation: Group the data based on categorical variables and calculate aggregated statistics (e.g., mean, median) for interval and ratio variables within each group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdd6b52-242b-4c39-987f-2e151d63efcd",
   "metadata": {},
   "source": [
    "To provide a conclusion based on the analysis of your data, you can follow these steps:\n",
    "\n",
    "Summarize Key Findings: Start by summarizing the key findings from your analysis. Highlight the most important insights and patterns that emerged from your data exploration and feature engineering. This could include significant relationships between variables, notable trends, or unexpected discoveries.\n",
    "\n",
    "Answer the Research Questions: Refer back to the initial research questions or objectives that guided your analysis. Assess whether you were able to answer those questions based on the findings from your data analysis. Clearly state the conclusions you have drawn for each research question.\n",
    "\n",
    "Discuss Implications and Insights: Discuss the implications of your findings and the insights they provide. Explain why the identified patterns or relationships are significant and how they can contribute to your overall understanding of the data or the problem you are trying to solve. Consider the potential impact of the insights on decision-making or future actions.\n",
    "\n",
    "Address Limitations: Acknowledge any limitations or caveats in your analysis. Discuss factors that may have influenced the results or areas where further investigation may be needed. This demonstrates a critical and objective perspective and helps contextualize the conclusions.\n",
    "\n",
    "Provide Recommendations: Based on your analysis, offer recommendations or suggestions for further actions. This could include areas for improvement, strategies for optimization, or potential areas of future research. Connect your recommendations directly to the insights and conclusions drawn from your analysis.\n",
    "\n",
    "Summarize the Conclusion: Finally, provide a concise and clear summary of the overall conclusion based on your analysis. Restate the main findings, insights, and recommendations in a way that reinforces the main message you want to convey."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simple",
   "language": "python",
   "name": "simple"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
